![alt text](image.png)
<h1 align="center"> Primeiro estudo utilizando visao computacional - Techable Machine</h1>

Ãndice;
## ğŸ“Œ DescriÃ§Ã£o do Projeto:
A cozinha Ã© um ambiente repleto de utensÃ­lios que facilitam o preparo das refeiÃ§Ãµes. No entanto, encontrar o utensÃ­lio certo pode ser um desafio, principalmente para quem tem pouco espaÃ§o de armazenamento ou para pessoas com deficiÃªncia visual. A InteligÃªncia Artificial (IA) pode ser uma aliada nessa tarefa, permitindo a detecÃ§Ã£o automÃ¡tica de utensÃ­lios de cozinha atravÃ©s de imagens.

Neste estudo de caso, utilizaremos o Teachable Machine do Google para desenvolver um modelo de IA capaz de identificar e classificar diferentes utensÃ­lios de cozinha a partir de fotografias. O modelo serÃ¡ construÃ­do de forma interativa e acessÃ­vel, utilizando uma interface amigÃ¡vel que nÃ£o exige conhecimentos tÃ©cnicos aprofundados.

Status do Projeto:<br>
![Static Badge](https://img.shields.io/badge/Status-Finished-green)

Funcionalidades e DemonstraÃ§Ã£o da AplicaÃ§Ã£o;
# :hammer:ğŸ“ŒEtapas do estudo
- `Etapa 1`: Coleta de dados:

    - `Etapa 1a`: Reunir um conjunto de imagens de diferentes utensÃ­lios de cozinha, categorizando-as por tipo (por exemplo talheres, panelas, utensÃ­lios de preparo).
    - `Etapa 1b`: Assegurar a qualidade das imagens, com boa iluminaÃ§Ã£o, foco nÃ­tido e ausÃªncia de objetos extras que possam interferir na detecÃ§Ã£o.
    - `Etapa 1c`: Dividir as imagens em dois conjuntos: um para treinamento do modelo e outro para teste.

- `Etapa 2`: Treinamento do modelo:

    - `Etapa 2a`: Acessar o Teachable Machine <https://teachablemachine.withgoogle.com> e selecionar a opÃ§Ã£o "ClassificaÃ§Ã£o de Imagem" e depois â€œImagem PadrÃ£oâ€.
    - `Etapa 2b`: Carregar o conjunto de imagens de treinamento, organizando-as por categoria (exemplo talheres, panelas, utensÃ­lios de preparo).
    - `Etapa 2c`: Ajustar os parÃ¢metros do modelo, como o nÃºmero de classes e o tamanho da imagem.
    - `Etapa 2d`: Treinar o modelo, monitorando seu desempenho atravÃ©s das mÃ©tricas de precisÃ£o e acurÃ¡cia. FaÃ§a testes mexendo nas configuraÃ§Ãµes avanÃ§adas Ã©pocas, batch size e learning rate.

- `Etapa 3`: Teste e avaliaÃ§Ã£o do modelo:

    - `Etapa 3a`: Carregar o conjunto de imagens de teste no Teachable Machine.
    - `Etapa 3b`: Observar como o modelo se comporta ao classificar as novas imagens, identificando erros e acertos.
    - `Etapa 3c`: Observar as mÃ©tricas de precisÃ£o e acurÃ¡cia do modelo para o conjunto de teste.
    - `Etapa 3d`: Analisar os resultados e identificar oportunidades para aprimorar o modelo.


- `Etapa 4`: Elaborar um relatÃ³rio em PDF detalhando o processo de desenvolvimento do modelo, incluindo:

     - `Etapa 4a`: DescriÃ§Ã£o dos objetivos e da metodologia utilizada.
     - `Etapa 4b`: Prints das principais etapas do projeto, incluindo da taxa de acurÃ¡cia final.
     - `Etapa 4c`: ExplicaÃ§Ã£o de como cada etapa foi realizada.
     - `Etapa 4d`: Justificativa tÃ©cnica dos resultados obtidos.
     - `Etapa 4e`: AnÃ¡lise crÃ­tica do desempenho do modelo e sugestÃµes de melhorias.

## ğŸ“ŒDemonstraÃ§Ã£o da AplicaÃ§Ã£o
[Esudo Techable Machine](Estudo-Teachable-Machine/TechableMachine.pdf)

## ğŸ“ŒAcesso ao Projeto
VocÃª pode acessar o modelo de classificaÃ§Ã£o de utensÃ­lios treinado no **Teachable Machine** de duas formas:

1. **Acesso Online (Recomendado)**  
   ğŸ‘‰ [Clique aqui para testar o modelo](LINK_DO_MODELO)  

2. **Executando localmente**  
   - Baixe os arquivos exportados do modelo na pasta `/model`.  
   - Utilize **TensorFlow.js** para rodar em aplicaÃ§Ãµes web, ou **TensorFlow Lite** para rodar em dispositivos mÃ³veis.  
   - Exemplo de uso em JavaScript:  

   ```javascript
   // Carregar modelo
   const model = await tmImage.load('model.json', 'metadata.json');
   // Fazer previsÃ£o
   const prediction = await model.predict(imagem);
   console.log(prediction);

## ğŸ“ŒTecnologias utilizadas
O projeto utilizou a Teachable Machine, plataforma do Google que permite treinar modelos de aprendizado de mÃ¡quina (machine learning) de forma acessÃ­vel, sem a necessidade de programar diretamente. Ela gera modelos de classificaÃ§Ã£o de imagens, sons ou poses que depois podem ser exportados para uso em aplicaÃ§Ãµes web ou mÃ³veis.

## ğŸ“ŒPessoas Contribuidoras
**-Renan Francisco de Paula**<br>
**-Jonas Luis da Silva**<br>
**-JoÃ£o Vitor Severo Oliveira**

## ğŸ“ŒLicenÃ§a
Este estudo foi desenvolvido para fins acadÃªmicos pelos autores **Renan Francisco de Paula**, **Jonas Luis da Silva** e **JoÃ£o Vitor Severo Oliveira**.  

O conteÃºdo estÃ¡ licenciado sob a **Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)**.  
Isso significa que vocÃª pode **compartilhar** e **adaptar** este material, desde que:  
- DÃª o devido **crÃ©dito aos autores**;  
- **NÃ£o utilize para fins comerciais**.  

ğŸ”— Saiba mais: [Creative Commons BY-NC 4.0](https://creativecommons.org/licenses/by-nc/4.0/)
